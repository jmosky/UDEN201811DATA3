{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages.\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "\n",
    "mongo_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get NASA Mars News."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape data from nasa.gov API.\n",
    "news_url = \"https://mars.nasa.gov/api/v1/news_items/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest\"\n",
    "header = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "resp = requests.get(news_url, headers=header)\n",
    "resp = resp.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the response.\n",
    "print(resp.keys())\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant data.\n",
    "articles = resp.get('items')\n",
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_df = pd.DataFrame.from_records(articles)\n",
    "article_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store title and content for later.\n",
    "titles = article_df['title']\n",
    "content = article_df['body']\n",
    "titles_content = article_df[['title','body']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get JPL Mars Space Images - Featured Image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image url.\n",
    "image_url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "    \n",
    "# Use splinter to navigate the site and find the image url for the current Featured \n",
    "# Mars Image and assign the url string to a variable called featured_image_url.\n",
    "    \n",
    "executable_path = {'executable_path': '/Users/jenniferwilson/Desktop/Repositories/UDEN201811DATA3-Homework/chromedriver'}\n",
    "browser = Browser('chrome', **executable_path)\n",
    "\n",
    "browser.visit(image_url)\n",
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "# How are these different\n",
    "#soup.find_all(\"article\",{\"class\":\"carousel_item\"})[0]\n",
    "#soup.find_all(\"article\",{\"class\":\"carousel_item\"})[0].contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From soup object above, get featured image URL.\n",
    "featured_image_url = \"https://www.jpl.nasa.gov\" + soup.article[\"style\"].split(\"'\")[1]\n",
    "featured_image_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Mars Weather."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_url = \"https://twitter.com/marswxreport?lang=en\"\n",
    "header = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "resp = requests.get(twitter_url, headers=header)\n",
    "soup = bs(resp.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract first tweet.\n",
    "tweet_text = soup.find(\"p\",{\"class\":\"TweetTextSize\"}).get_text()\n",
    "\n",
    "# Remove ASCII characters.\n",
    "tweet_text = tweet_text.encode(\"ascii\",\"ignore\")\n",
    "\n",
    "# Split based on line breaks.\n",
    "mars_weather = tweet_text.splitlines()\n",
    "\n",
    "mars_weather\n",
    "\n",
    "# Output should look like this:\n",
    "#InSight sol 88 (2019-02-25) low -95.2ºC (-139.4ºF) high -17.8ºC (0.0ºF)\n",
    "#winds from the SW at 5.2 m/s (11.6 mph) gusting to 19.8 m/s (44.3 mph)\n",
    "#pressure at 7.20 hPa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc.\n",
    "def get_facts():\n",
    "    facts_url = \"http://space-facts.com/mars/\"\n",
    "    facts = pd.read_html(facts_url)\n",
    "    facts_df = facts[0]\n",
    "    facts_df.rename(columns={0: \"Stat\", 1:\"Values\"}, inplace = True) \n",
    "    facts_df['Values'] = map(lambda x: x.encode('ascii', 'ignore').decode('ascii'), facts_df[\"Values\"])\n",
    "    facts_html = facts_df.to_html()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pandas to convert the data to a HTML table string.\n",
    "# https://stackoverflow.com/questions/3206344/passing-html-to-template-using-flask-jinja2\n",
    "facts_html = facts_df.to_html()\n",
    "print(facts_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape starting page for the URLs to each hemisphere page.\n",
    "image_page_urls = []\n",
    "\n",
    "def get_hemisphere_urls():\n",
    "    url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "    header = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "    resp = requests.get(url, headers=header)\n",
    "    soup = bs(resp.text,'html.parser')\n",
    "    hrefs = soup.find_all(\"a\", {\"class\": \"itemLink product-item\"})\n",
    "    \n",
    "    for i in range(len(hrefs)):\n",
    "        href_trimmed = hrefs[i]['href'].encode('utf-8')\n",
    "        image_page_urls.append(\"https://astrogeology.usgs.gov/\" + href_trimmed)\n",
    "\n",
    "get_hemisphere_urls()\n",
    "print(image_page_urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://astrogeology.usgs.gov//search/map/Mars/Viking/cerberus_enhanced\"\n",
    "header = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "resp = requests.get(url, headers=header)\n",
    "soup = bs(resp.text,'html.parser')\n",
    "\n",
    "image_url = soup.find_all(\"a\", attrs={\"target\": \"_blank\"})\n",
    "image_url = image_url[1][\"href\"]\n",
    "\n",
    "title = soup.find('h2', {\"class\":\"title\"}).get_text().encode('utf-8')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemisphere_image_urls = []\n",
    "\n",
    "def get_hemisphere_image():\n",
    "    for i in range(len(image_page_urls)):\n",
    "        url = image_page_urls[i]        \n",
    "        header = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "        resp = requests.get(url, headers=header)\n",
    "        soup = bs(resp.text,'html.parser')\n",
    "        \n",
    "        image_url = soup.find_all(\"a\", attrs={\"target\": \"_blank\"})\n",
    "        image_url = image_url[1][\"href\"].encode('utf-8')\n",
    "        title = soup.find('h2', {\"class\":\"title\"}).get_text().encode('utf-8')\n",
    "        \n",
    "        hemisphere_image_urls.append({\n",
    "            \"img_url\": image_url,\n",
    "            \"title\": title,\n",
    "        })\n",
    "        \n",
    "get_hemisphere_image()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hemisphere_image_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it together into one dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages.\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "\n",
    "mongo_dict = {\n",
    "    \"news\":\"\",\n",
    "    \"featured_image\":\"\",\n",
    "    \"weather\":\"\",\n",
    "    \"facts\":\"\",\n",
    "    \"images\":\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get NASA Mars News and store results as a list of dictionaries.\n",
    "\n",
    "def get_articles():\n",
    "    news = []\n",
    "    \n",
    "    news_url = \"https://mars.nasa.gov/api/v1/news_items/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest\"\n",
    "    header = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "    resp = requests.get(news_url, headers=header)\n",
    "    resp = resp.json()\n",
    "\n",
    "    # Get articls\n",
    "    articles = resp.get('items')\n",
    "    \n",
    "    # Iterate over all elements in articles to extract title and body.\n",
    "    for i in range(len(articles)):\n",
    "        # Store title.\n",
    "        title = articles[i]['title'].encode('utf-8')\n",
    "\n",
    "        # Store body.\n",
    "        body = articles[i]['body'].encode('utf-8')\n",
    "        body = re.sub(r'<.*?>', '', body)\n",
    "        \n",
    "        \n",
    "        news.append({\n",
    "            \"title\": title,\n",
    "            \"body\": body,\n",
    "        })\n",
    "        \n",
    "        print(news)\n",
    "        #mongo_dict.update({\"news\":UPDATE})\n",
    "\n",
    "get_articles()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get JPL Mars Space Images - Featured Image.\n",
    "featured_image = []\n",
    "\n",
    "def get_featured_image():\n",
    "    image_url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"    \n",
    "    executable_path = {'executable_path': '/Users/jenniferwilson/Desktop/Repositories/UDEN201811DATA3-Homework/chromedriver'}\n",
    "    browser = Browser('chrome', **executable_path)\n",
    "    browser.visit(image_url)\n",
    "    html = browser.html\n",
    "    soup = bs(html, 'html.parser')\n",
    "    featured_image_url = \"https://www.jpl.nasa.gov\" + soup.article[\"style\"].split(\"'\")[1].encode('utf-8')\n",
    "    featured_image.append({\"featured_image_url\": featured_image_url})\n",
    "    \n",
    "get_featured_image()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Mars weather.\n",
    "weather = []\n",
    "\n",
    "def get_mars_weather():\n",
    "    twitter_url = \"https://twitter.com/marswxreport?lang=en\"\n",
    "    header = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "    resp = requests.get(twitter_url, headers=header)\n",
    "    soup = bs(resp.text,'html.parser')\n",
    "\n",
    "    # Extract first tweet.\n",
    "    tweet_text = soup.find(\"p\",{\"class\":\"TweetTextSize\"}).get_text()\n",
    "\n",
    "    # Remove ASCII characters.\n",
    "    tweet_text = str(tweet_text.encode(\"ascii\",\"ignore\"))\n",
    "    \n",
    "    weather.append({\"weather\": tweet_text})\n",
    "    \n",
    "get_mars_weather()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Mars facts.\n",
    "facts = []\n",
    "\n",
    "def get_facts():\n",
    "    facts_url = \"http://space-facts.com/mars/\"\n",
    "    facts = pd.read_html(facts_url)\n",
    "    facts_df = facts[0]\n",
    "    facts_df.rename(columns={0: \"Stat\", 1:\"Values\"}, inplace = True) \n",
    "    facts_df['Values'] = map(lambda x: x.encode('ascii', 'ignore').decode('ascii'), facts_df[\"Values\"])\n",
    "    facts_html = facts_df.to_html()\n",
    "    print(facts_html)\n",
    "    facts.append({\"facts:\":facts_html})\n",
    "\n",
    "get_facts()\n",
    "facts\n",
    "\n",
    "# TUTOR - Doesn't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get hemisphere images.\n",
    "\n",
    "image_page_urls = []\n",
    "\n",
    "def get_hemisphere_urls():\n",
    "    url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "    header = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "    resp = requests.get(url, headers=header)\n",
    "    soup = bs(resp.text,'html.parser')\n",
    "    hrefs = soup.find_all(\"a\", {\"class\": \"itemLink product-item\"})\n",
    "    \n",
    "    for i in range(len(hrefs)):\n",
    "        href_trimmed = hrefs[i]['href'].encode('utf-8')\n",
    "        image_page_urls.append(\"https://astrogeology.usgs.gov/\" + href_trimmed)\n",
    "\n",
    "get_hemisphere_urls()\n",
    "\n",
    "hemisphere_image_urls = []\n",
    "\n",
    "def get_hemisphere_image():\n",
    "    for i in range(len(image_page_urls)):\n",
    "        url = image_page_urls[i]        \n",
    "        header = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "        resp = requests.get(url, headers=header)\n",
    "        soup = bs(resp.text,'html.parser')\n",
    "        \n",
    "        image_url = soup.find_all(\"a\", attrs={\"target\": \"_blank\"})\n",
    "        image_url = image_url[1][\"href\"].encode('utf-8')\n",
    "        title = soup.find('h2', {\"class\":\"title\"}).get_text().encode('utf-8')\n",
    "        \n",
    "        hemisphere_image_urls.append({\n",
    "            \"img_url\": image_url,\n",
    "            \"title\": title,\n",
    "        })\n",
    "        \n",
    "get_hemisphere_image()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
